{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Titanic survival - optimising models with grid search and random search\n",
    "\n",
    "Machine learning models have many hyper-parameters (parameters set before a model is fitted, and which remain constant throughout model fitting). Optimising model hyper-parameters may involve many model runs with alternative hyper-parameters. In SciKit-Learn, this may be performed in an automated fashion using `GridSearchCV` (which explores all combinations of provided hyper-parameters) or `RandomizedSearchCV` (which selects randomly from parameter ranges, which can be useful when there are too many combinations in grid search).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will go through the following steps:\n",
    "\n",
    "* Download and save pre-processed data\n",
    "* Split data into features (X) and label (y)\n",
    "* Standardise data\n",
    "* Use grid search to optimise model parameters\n",
    "\n",
    "`GridSearchCV` used stratified k-fold sampling to perform replicates for each parameter step. If you are unfamiliar with this method of replication have a look at:\n",
    "\n",
    "https://github.com/MichaelAllen1966/1804_python_healthcare/blob/master/titanic/03_k_fold.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hide warnings (to keep notebook tidy; do not usually do this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hide warnings (to keep notebook tidy; do not usually do this)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules\n",
    "\n",
    "A standard Anaconda install of Python (https://www.anaconda.com/distribution/) contains all the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Import machine learning methods\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "The section below downloads pre-processed data, and saves it to a subfolder (from where this code is run).\n",
    "If data has already been downloaded that cell may be skipped.\n",
    "\n",
    "Code that was used to pre-process the data ready for machine learning may be found at:\n",
    "https://github.com/MichaelAllen1966/1804_python_healthcare/blob/master/titanic/01_preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_required = True\n",
    "\n",
    "if download_required:\n",
    "    \n",
    "    # Download processed data:\n",
    "    address = 'https://raw.githubusercontent.com/MichaelAllen1966/' + \\\n",
    "                '1804_python_healthcare/master/titanic/data/processed_data.csv'\n",
    "    \n",
    "    data = pd.read_csv(address)\n",
    "\n",
    "    # Create a data subfolder if one does not already exist\n",
    "    import os\n",
    "    data_directory ='./data/'\n",
    "    if not os.path.exists(data_directory):\n",
    "        os.makedirs(data_directory)\n",
    "\n",
    "    # Save data\n",
    "    data.to_csv(data_directory + 'processed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/processed_data.csv')\n",
    "# Make all data 'float' type\n",
    "data = data.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column is a passenger index number. We will remove this, as this is not part of the original Titanic passenger data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Passengerid (axis=1 indicates we are removing a column rather than a row)\n",
    "# We drop passenger ID as it is not original data\n",
    "\n",
    "data.drop('PassengerId', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide into X (features) and y (labels)\n",
    "\n",
    "We will separate out our features (the data we use to make a prediction) from our label (what we are truing to predict).\n",
    "By convention our features are called `X` (usually upper case to denote multiple features), and the label (survive or not) `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Survived',axis=1) # X = all 'data' except the 'survived' column\n",
    "y = data['Survived'] # y = 'survived' column from 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardise data\n",
    "\n",
    "For grid and random search we will standardise data just once at the beginning. Note - for final model testing you should follow the normal practice of splitting the data into training and test data sets, and standardising both sets of data based on the training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise a new scaling object for normalising input data\n",
    "sc = StandardScaler() \n",
    "\n",
    "# Set up the scaler just on the training set\n",
    "sc.fit(X)\n",
    "\n",
    "# Apply the scaler to the X data\n",
    "X_std=sc.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search\n",
    "\n",
    "Grid serach is a good method so long as the number of paramater combinations is not too high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining parameters to test\n",
    "\n",
    "We define parameters to test in a dictionary.\n",
    "\n",
    "NOTE: Grid search can very quickly lead to very many parameters to test. Initially it is best to pick just 2-3 levels of each parameter. You can always narrow the search.\n",
    "\n",
    "The parameters available for tuning for the logistic regression model are listed on the document page for the model (you can also find this using the `help()` method in Python:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will vary the following in grid search (and will expand the list in random search):\n",
    "\n",
    "* penalty type (for regularisation)\n",
    "* Regularisation (C)\n",
    "* Class weight. 38% of the passengers survive. This can lead to survivors having less influence in the model (as there are fewer of them). We will test weighting non-survivors and survivors in inverse proportion to their number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'penalty': ['l1', 'l2'],\n",
    "              'C': [0.01, 0.1, 1, 10],\n",
    "              'class_weight': [{0:0.5, 1:0.5},{0:0.38, 1:0.62}]}\n",
    "\n",
    "# Class weight is defined as a dictionary with class label and weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above paraemter grid we have 2 * 4 * 2 parameter combinations = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run grid search with defined parameters\n",
    "\n",
    "We run the grid search, defining the number of k-fold replicates to use, and we specify the accuracy measurement we want to report (in this case we will use 'f1' to balance precision and recall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Define grid search to use 5 k-fold validation, and use 'f1' for accuracy\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Run grid search\n",
    "grid_search.fit(X_std, y); #';' suppresses printed output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show grid search performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performance (f1):\n",
      "0.7355099445362381\n",
      "Best parameters:\n",
      "{'C': 0.1, 'class_weight': {0: 0.38, 1: 0.62}, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# show best performance and parameters\n",
    "# If best parameters are at the extremes of the searches then extend the range\n",
    "\n",
    "print ('Best performance (f1):')\n",
    "print (grid_search.best_score_)\n",
    "print ('Best parameters:')\n",
    "print (grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, show full description (which may be copied in to a model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight={0: 0.38, 1: 0.62}, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full results are stored in a dictionary `cv_results_`. Below we display them by passing them to a Pandas DataFrame (and we limit the columns to those of most interest to us)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   param_penalty param_C  param_class_weight  mean_test_score  rank_test_score\n",
      "0             l1    0.01    {0: 0.5, 1: 0.5}         0.000000               15\n",
      "1             l2    0.01    {0: 0.5, 1: 0.5}         0.714713               13\n",
      "2             l1    0.01  {0: 0.38, 1: 0.62}         0.000000               15\n",
      "3             l2    0.01  {0: 0.38, 1: 0.62}         0.730961                2\n",
      "4             l1     0.1    {0: 0.5, 1: 0.5}         0.709479               14\n",
      "5             l2     0.1    {0: 0.5, 1: 0.5}         0.722657                8\n",
      "6             l1     0.1  {0: 0.38, 1: 0.62}         0.724712                6\n",
      "7             l2     0.1  {0: 0.38, 1: 0.62}         0.735510                1\n",
      "8             l1       1    {0: 0.5, 1: 0.5}         0.721540                9\n",
      "9             l2       1    {0: 0.5, 1: 0.5}         0.720458               11\n",
      "10            l1       1  {0: 0.38, 1: 0.62}         0.723316                7\n",
      "11            l2       1  {0: 0.38, 1: 0.62}         0.729697                3\n",
      "12            l1      10    {0: 0.5, 1: 0.5}         0.720458               11\n",
      "13            l2      10    {0: 0.5, 1: 0.5}         0.720487               10\n",
      "14            l1      10  {0: 0.38, 1: 0.62}         0.727679                4\n",
      "15            l2      10  {0: 0.38, 1: 0.62}         0.727679                4\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "cols_to_show = ['param_penalty','param_C', 'param_class_weight',\n",
    "                'mean_test_score','rank_test_score' ]\n",
    "print(results[cols_to_show])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at the results, it is worth noting the range of results. Tou may then consider whether it is worth refining the grid search to focus on a narrower area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random search\n",
    "\n",
    "Random search is very similar to grid search, but randomly selects combinations of parameters to test, with the maximum number of tests given by the `n_iter` argument.\n",
    "\n",
    "As we've been through the process with grid search, we'll put all our code together here, but note the larger number of parameters defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performance (f1):\n",
      "0.7355099445362381\n",
      "Best parameters:\n",
      "{'penalty': 'l2', 'max_iter': 100, 'class_weight': {0: 0.38, 1: 0.62}, 'C': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import GridSearch\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define paraemter grid and maximum number of tests\n",
    "\n",
    "param_grid = {'penalty': ['l1', 'l2'],\n",
    "              'C': [0.01, 0.03, 0.1, 0.3, 1, 3, 10],\n",
    "              'class_weight': [{0:0.5, 1:0.5},\n",
    "                               {0:0.38, 1:0.62},\n",
    "                               {0:0.62, 1:0.38}],\n",
    "              'max_iter': [30, 100, 300, 1000]}\n",
    "\n",
    "n_iter_search = 50\n",
    "\n",
    "# Define model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Set up random search\n",
    "random_search = RandomizedSearchCV(model, param_grid, cv=5,\n",
    "                           n_iter=n_iter_search, scoring='f1')\n",
    "\n",
    "# Run grid search\n",
    "random_search.fit(X_std, y); #';' suppresses printed output\n",
    "\n",
    "# Get and print output\n",
    "print ('Best performance (f1):')\n",
    "print (random_search.best_score_)\n",
    "print ('Best parameters:')\n",
    "print (random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   param_penalty param_C  param_class_weight  mean_test_score  rank_test_score\n",
      "0             l1       3    {0: 0.5, 1: 0.5}         0.721539               13\n",
      "1             l2    0.03    {0: 0.5, 1: 0.5}         0.731564                2\n",
      "2             l2     0.3  {0: 0.62, 1: 0.38}         0.714191               21\n",
      "3             l1       3  {0: 0.62, 1: 0.38}         0.704302               33\n",
      "4             l1      10    {0: 0.5, 1: 0.5}         0.720458               16\n",
      "5             l1     0.3    {0: 0.5, 1: 0.5}         0.721433               14\n",
      "6             l1     0.1  {0: 0.38, 1: 0.62}         0.724712                7\n",
      "7             l1     0.1  {0: 0.38, 1: 0.62}         0.724712                7\n",
      "8             l2      10  {0: 0.62, 1: 0.38}         0.703537               36\n",
      "9             l2    0.01  {0: 0.62, 1: 0.38}         0.650990               43\n",
      "10            l2      10  {0: 0.38, 1: 0.62}         0.727679                6\n",
      "11            l2      10    {0: 0.5, 1: 0.5}         0.720487               15\n",
      "12            l1       1  {0: 0.62, 1: 0.38}         0.704254               35\n",
      "13            l2    0.03  {0: 0.62, 1: 0.38}         0.692330               41\n",
      "14            l1    0.01    {0: 0.5, 1: 0.5}         0.000000               46\n",
      "15            l1     0.1    {0: 0.5, 1: 0.5}         0.709479               25\n",
      "16            l1    0.01  {0: 0.62, 1: 0.38}         0.000000               46\n",
      "17            l2     0.3  {0: 0.62, 1: 0.38}         0.714191               21\n",
      "18            l1    0.01  {0: 0.38, 1: 0.62}         0.000000               46\n",
      "19            l1       1    {0: 0.5, 1: 0.5}         0.721540               10\n",
      "20            l1     0.3  {0: 0.38, 1: 0.62}         0.722912                9\n",
      "21            l2     0.3  {0: 0.38, 1: 0.62}         0.730898                4\n",
      "22            l1    0.01  {0: 0.38, 1: 0.62}         0.000000               46\n",
      "23            l1    0.01  {0: 0.62, 1: 0.38}         0.000000               46\n",
      "24            l1       1    {0: 0.5, 1: 0.5}         0.721540               10\n",
      "25            l1      10    {0: 0.5, 1: 0.5}         0.720458               16\n",
      "26            l2     0.1  {0: 0.62, 1: 0.38}         0.711792               23\n",
      "27            l1     0.1    {0: 0.5, 1: 0.5}         0.709479               25\n",
      "28            l2    0.01  {0: 0.38, 1: 0.62}         0.730961                3\n",
      "29            l1     0.3  {0: 0.62, 1: 0.38}         0.695724               40\n",
      "30            l1    0.03  {0: 0.38, 1: 0.62}         0.709217               27\n",
      "31            l2       1  {0: 0.38, 1: 0.62}         0.729697                5\n",
      "32            l2       3    {0: 0.5, 1: 0.5}         0.720458               16\n",
      "33            l1    0.03  {0: 0.38, 1: 0.62}         0.709217               27\n",
      "34            l2    0.03  {0: 0.62, 1: 0.38}         0.692330               41\n",
      "35            l1       3  {0: 0.62, 1: 0.38}         0.704302               33\n",
      "36            l2     0.1  {0: 0.38, 1: 0.62}         0.735510                1\n",
      "37            l1    0.03    {0: 0.5, 1: 0.5}         0.709217               27\n",
      "38            l1      10  {0: 0.62, 1: 0.38}         0.703537               36\n",
      "39            l1    0.03  {0: 0.38, 1: 0.62}         0.709217               27\n",
      "40            l2       1    {0: 0.5, 1: 0.5}         0.720458               16\n",
      "41            l1      10  {0: 0.62, 1: 0.38}         0.703537               36\n",
      "42            l2       3  {0: 0.62, 1: 0.38}         0.702510               39\n",
      "43            l2    0.01  {0: 0.62, 1: 0.38}         0.650990               43\n",
      "44            l2    0.01  {0: 0.62, 1: 0.38}         0.650990               43\n",
      "45            l2       1  {0: 0.62, 1: 0.38}         0.706706               31\n",
      "46            l2       1    {0: 0.5, 1: 0.5}         0.720458               16\n",
      "47            l1       1    {0: 0.5, 1: 0.5}         0.721540               10\n",
      "48            l2       1  {0: 0.62, 1: 0.38}         0.706706               31\n",
      "49            l2     0.1  {0: 0.62, 1: 0.38}         0.711792               23\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(random_search.cv_results_)\n",
    "cols_to_show = ['param_penalty','param_C', 'param_class_weight',\n",
    "                'mean_test_score','rank_test_score' ]\n",
    "print(results[cols_to_show])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this small example we have found grid search and random search both identified a solution with the same accuracy, and in good time. In larger models you may find it best to run a random search initially (which helps to show which parameters are most influential), and then use a grid search once you have narrowed down the area of search."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
