{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Titanic survival - Dealing with imbalanced data by enhancing the minority class with synthetic data (SMOTE: Synthetic Minority Over-sampling Technique)\n",
    "\n",
    "\n",
    "A problem with machine learning models is that they may end up biased towards the majority class, and under-predict the minority class(es).\n",
    "\n",
    "Some models (including sklearn's logistic regression) allow for thresholds of classification to be changed. This can help rebalance classification in models, especially where there is a binary classification (e.g. survived or not).\n",
    "\n",
    "Here we create a more imbalanced data set from the Titanic set, by dropping half the survivors.\n",
    "\n",
    "We then enhance the minority class with synthetic data using a technique called Synthetic Minority Over-sampling Technique (SMOTE). Essentially, SMOTE creates new cases by interpolating between two existing near-neighbough cases. SMOTE rebalances the data set, synthetically enhancing the minority class so that the number of minority examples are increased to match the number of majority samples.\n",
    "\n",
    "We will use a package, imblearn, for this method. You may install with with: `pip install -U imbalanced-learn`, or `conda install -c conda-forge imbalanced-learn`.\n",
    "\n",
    "We will use the `SMOTENC` method as that allows us to create synthetic data where some of the fields are categorical, rather than continuous, data. For categorical data, this method identifies *k* nearest neighbours and sets a feature label as the most common value among those near neighbours.\n",
    "\n",
    "More on imblearn here: https://imbalanced-learn.org/stable/\n",
    "\n",
    "*Reference*\n",
    "\n",
    "N. V. Chawla, K. W. Bowyer, L. O.Hall, W. P. Kegelmeyer, “SMOTE: synthetic minority over-sampling technique,” Journal of artificial intelligence research, 16, 321-357, 2002\n",
    "\n",
    "In this notebook we will:\n",
    "* Fit a model without SMOTE\n",
    "* Fit a model with SMOTE\n",
    "* Fine-tune SMOTE to correctly predict the proportion of passengers surviving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hide warnings (to keep notebook tidy; do not usually do this)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules\n",
    "\n",
    "A standard Anaconda install of Python (https://www.anaconda.com/distribution/) contains all the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Import machine learning methods\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "The section below downloads pre-processed data, and saves it to a subfolder (from where this code is run).\n",
    "If data has already been downloaded that cell may be skipped.\n",
    "\n",
    "Code that was used to pre-process the data ready for machine learning may be found at:\n",
    "https://github.com/MichaelAllen1966/1804_python_healthcare/blob/master/titanic/01_preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_required = True\n",
    "\n",
    "if download_required:\n",
    "    \n",
    "    # Download processed data:\n",
    "    address = 'https://raw.githubusercontent.com/MichaelAllen1966/' + \\\n",
    "                '1804_python_healthcare/master/titanic/data/processed_data.csv'\n",
    "    \n",
    "    data = pd.read_csv(address)\n",
    "\n",
    "    # Create a data subfolder if one does not already exist\n",
    "    import os\n",
    "    data_directory ='./data/'\n",
    "    if not os.path.exists(data_directory):\n",
    "        os.makedirs(data_directory)\n",
    "\n",
    "    # Save data\n",
    "    data.to_csv(data_directory + 'processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/processed_data.csv')\n",
    "# Make all data 'float' type\n",
    "data = data.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column is a passenger index number. We will remove this, as this is not part of the original Titanic passenger data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Passengerid (axis=1 indicates we are removing a column rather than a row)\n",
    "# We drop passenger ID as it is not original data\n",
    "\n",
    "data.drop('PassengerId', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificially reduce the number of survivors (to make data set more imbalanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion survived: 0.238\n"
     ]
    }
   ],
   "source": [
    "# Shuffle original data\n",
    "data = data.sample(frac=1.0) # Sampling with a fraction of 1.0 shuffles data\n",
    "\n",
    "# Create masks for filters\n",
    "mask_died = data['Survived'] == 0\n",
    "mask_survived = data['Survived'] == 1\n",
    "\n",
    "# Filter data\n",
    "died = data[mask_died]\n",
    "survived = data[mask_survived]\n",
    "\n",
    "# Reduce survived by half\n",
    "survived = survived.sample(frac=0.5)\n",
    "\n",
    "# Recombine data and shuffle\n",
    "data = pd.concat([died, survived])\n",
    "data = data.sample(frac=1.0) \n",
    "\n",
    "# Show average of survived\n",
    "survival_rate = data['Survived'].mean()\n",
    "print ('Proportion survived:', np.round(survival_rate,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function to standardise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardise_data(X_train, X_test):\n",
    "    \n",
    "    # Initialise a new scaling object for normalising input data\n",
    "    sc = StandardScaler() \n",
    "\n",
    "    # Set up the scaler just on the training set\n",
    "    sc.fit(X_train)\n",
    "\n",
    "    # Apply the scaler to the training and test sets\n",
    "    train_std=sc.transform(X_train)\n",
    "    test_std=sc.transform(X_test)\n",
    "    \n",
    "    return train_std, test_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function to measure accuracy\n",
    "\n",
    "The following is a function for multiple accuracy measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(observed, predicted):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculates a range of accuracy scores from observed and predicted classes.\n",
    "    \n",
    "    Takes two list or NumPy arrays (observed class values, and predicted class \n",
    "    values), and returns a dictionary of results.\n",
    "    \n",
    "     1) observed positive rate: proportion of observed cases that are +ve\n",
    "     2) Predicted positive rate: proportion of predicted cases that are +ve\n",
    "     3) observed negative rate: proportion of observed cases that are -ve\n",
    "     4) Predicted negative rate: proportion of predicted cases that are -ve  \n",
    "     5) accuracy: proportion of predicted results that are correct    \n",
    "     6) precision: proportion of predicted +ve that are correct\n",
    "     7) recall: proportion of true +ve correctly identified\n",
    "     8) f1: harmonic mean of precision and recall\n",
    "     9) sensitivity: Same as recall\n",
    "    10) specificity: Proportion of true -ve identified:        \n",
    "    11) positive likelihood: increased probability of true +ve if test +ve\n",
    "    12) negative likelihood: reduced probability of true +ve if test -ve\n",
    "    13) false positive rate: proportion of false +ves in true -ve patients\n",
    "    14) false negative rate: proportion of false -ves in true +ve patients\n",
    "    15) true positive rate: Same as recall\n",
    "    16) true negative rate\n",
    "    17) positive predictive value: chance of true +ve if test +ve\n",
    "    18) negative predictive value: chance of true -ve if test -ve\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Converts list to NumPy arrays\n",
    "    if type(observed) == list:\n",
    "        observed = np.array(observed)\n",
    "    if type(predicted) == list:\n",
    "        predicted = np.array(predicted)\n",
    "    \n",
    "    # Calculate accuracy scores\n",
    "    observed_positives = observed == 1\n",
    "    observed_negatives = observed == 0\n",
    "    predicted_positives = predicted == 1\n",
    "    predicted_negatives = predicted == 0\n",
    "    \n",
    "    true_positives = (predicted_positives == 1) & (observed_positives == 1)\n",
    "    \n",
    "    false_positives = (predicted_positives == 1) & (observed_positives == 0)\n",
    "    \n",
    "    true_negatives = (predicted_negatives == 1) & (observed_negatives == 1)\n",
    "    \n",
    "    accuracy = np.mean(predicted == observed)\n",
    "    \n",
    "    precision = (np.sum(true_positives) /\n",
    "                 (np.sum(true_positives) + np.sum(false_positives)))\n",
    "        \n",
    "    recall = np.sum(true_positives) / np.sum(observed_positives)\n",
    "    \n",
    "    sensitivity = recall\n",
    "    \n",
    "    f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "    \n",
    "    specificity = np.sum(true_negatives) / np.sum(observed_negatives)\n",
    "    \n",
    "    positive_likelihood = sensitivity / (1 - specificity)\n",
    "    \n",
    "    negative_likelihood = (1 - sensitivity) / specificity\n",
    "    \n",
    "    false_positive_rate = 1 - specificity\n",
    "    \n",
    "    false_negative_rate = 1 - sensitivity\n",
    "    \n",
    "    true_positive_rate = sensitivity\n",
    "    \n",
    "    true_negative_rate = specificity\n",
    "    \n",
    "    positive_predictive_value = (np.sum(true_positives) / \n",
    "                                 np.sum(observed_positives))\n",
    "    \n",
    "    negative_predictive_value = (np.sum(true_negatives) / \n",
    "                                  np.sum(observed_positives))\n",
    "    \n",
    "    # Create dictionary for results, and add results\n",
    "    results = dict()\n",
    "    \n",
    "    results['observed_positive_rate'] = np.mean(observed_positives)\n",
    "    results['observed_negative_rate'] = np.mean(observed_negatives)\n",
    "    results['predicted_positive_rate'] = np.mean(predicted_positives)\n",
    "    results['predicted_negative_rate'] = np.mean(predicted_negatives)\n",
    "    results['accuracy'] = accuracy\n",
    "    results['precision'] = precision\n",
    "    results['recall'] = recall\n",
    "    results['f1'] = f1\n",
    "    results['sensitivity'] = sensitivity\n",
    "    results['specificity'] = specificity\n",
    "    results['positive_likelihood'] = positive_likelihood\n",
    "    results['negative_likelihood'] = negative_likelihood\n",
    "    results['false_positive_rate'] = false_positive_rate\n",
    "    results['false_negative_rate'] = false_negative_rate\n",
    "    results['true_positive_rate'] = true_positive_rate\n",
    "    results['true_negative_rate'] = true_negative_rate\n",
    "    results['positive_predictive_value'] = positive_predictive_value\n",
    "    results['negative_predictive_value'] = negative_predictive_value\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide into X (features) and y (labels)\n",
    "\n",
    "We will separate out our features (the data we use to make a prediction) from our label (what we are truing to predict).\n",
    "By convention our features are called `X` (usually upper case to denote multiple features), and the label (survive or not) `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Survived',axis=1) # X = all 'data' except the 'survived' column\n",
    "y = data['Survived'] # y = 'survived' column from 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up DataFrame to hold results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_names = ['accuracy', 'precision', 'recall', 'f1', \n",
    "                 'predicted positive rate', 'observed positive rate']\n",
    "\n",
    "results = pd.DataFrame(index = results_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data from Pandas DataFrame to NumPy\n",
    "\n",
    "This is required for k-fold validation.\n",
    "\n",
    "If you are unfamiliar with k-fold validation please see:\n",
    "\n",
    "https://github.com/MichaelAllen1966/1804_python_healthcare/blob/master/titanic/03_k_fold.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NumPy arrays of X and y (required for k-fold)\n",
    "X_np = X.values\n",
    "y_np = y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        non_smote\n",
      "accuracy                 0.854167\n",
      "precision                0.776072\n",
      "recall                   0.562092\n",
      "f1                       0.643747\n",
      "predicted positive rate   0.175000\n",
      "observed positive rate   0.237500\n"
     ]
    }
   ],
   "source": [
    "# Set up lists to hold results for each k-fold run\n",
    "replicate_accuracy = []\n",
    "replicate_precision = []\n",
    "replicate_recall = []\n",
    "replicate_f1 = []\n",
    "replicate_predicted_positive_rate = []\n",
    "replicate_observed_positive_rate = []\n",
    "\n",
    "# Set up splits\n",
    "number_of_splits = 10\n",
    "skf = StratifiedKFold(n_splits = number_of_splits)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "# Loop through the k-fold splits\n",
    "for train_index, test_index in skf.split(X_np, y_np):\n",
    "    \n",
    "    # Get X and Y train/test\n",
    "    X_train, X_test = X_np[train_index], X_np[test_index]\n",
    "    y_train, y_test = y_np[train_index], y_np[test_index]\n",
    "    \n",
    "    # Standardise X data\n",
    "    X_train_std, X_test_std = standardise_data(X_train, X_test)\n",
    "    \n",
    "    # Set up and fit model\n",
    "    model = LogisticRegression(solver='lbfgs')\n",
    "    model.fit(X_train_std,y_train)\n",
    "    \n",
    "    # Predict training and test set labels\n",
    "    y_pred_train = model.predict(X_train_std)\n",
    "    y_pred_test = model.predict(X_test_std)\n",
    "    \n",
    "    # Predict test set labels and get accuracy scores\n",
    "    y_pred_test = model.predict(X_test_std)\n",
    "    accuracy_scores = calculate_accuracy(y_test, y_pred_test)\n",
    "    replicate_accuracy.append(accuracy_scores['accuracy'])\n",
    "    replicate_precision.append(accuracy_scores['precision'])\n",
    "    replicate_recall.append(accuracy_scores['recall'])\n",
    "    replicate_f1.append(accuracy_scores['f1'])\n",
    "    replicate_predicted_positive_rate.append(\n",
    "        accuracy_scores['predicted_positive_rate'])\n",
    "    replicate_observed_positive_rate.append(\n",
    "        accuracy_scores['observed_positive_rate'])\n",
    "    \n",
    "# Transfer results to list and add to data frame\n",
    "non_smote_results = [np.mean(replicate_accuracy),\n",
    "                     np.mean(replicate_precision),\n",
    "                     np.mean(replicate_recall),\n",
    "                     np.mean(replicate_f1),\n",
    "                     np.mean(replicate_predicted_positive_rate),\n",
    "                     np.mean(replicate_observed_positive_rate)]\n",
    "\n",
    "results['non_smote'] = non_smote_results\n",
    "\n",
    "print (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression with SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an array to show which features are categorical\n",
    "In our data set only age and fare are continuous variables. All the other are categorical - that is they are one of a list of descrete values.\n",
    "\n",
    "So we shall create a series from feature names, set all of then original to categorical, and then change age and fair to categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set Age to non-categorical\n",
      "Set Fare to non-categorical\n",
      "Categorical features\n",
      "[ 0  2  3  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n"
     ]
    }
   ],
   "source": [
    "# Create an array of ones for all features\n",
    "number_of_features = X.shape[1]\n",
    "categorical_array = np.ones(number_of_features)\n",
    "\n",
    "# Create list of non-categorigcal features\n",
    "non_cat = ['Age','Fare']\n",
    "\n",
    "# Assign non_categorical features in our 'categorical' array\n",
    "features = list(X)\n",
    "for index, feature in enumerate(features):\n",
    "    if feature in non_cat:\n",
    "        print ('Set {:} to non-categorical'.format(feature))\n",
    "        categorical_array[index] = 0\n",
    " \n",
    "# Get catagorical indices\n",
    "categorical = np.where(categorical_array == 1)[0]\n",
    "\n",
    "# Print our categorical array\n",
    "print ('Categorical features')\n",
    "print (categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert X & y to NumPy arrays (required for k-fold stratification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np = X.values\n",
    "y_np = y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit logistic regression model (including SMOTE expansion of training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        non_smote     smote\n",
      "accuracy                 0.854167  0.811111\n",
      "precision                0.776072  0.590665\n",
      "recall                   0.562092  0.702288\n",
      "f1                       0.643747  0.637948\n",
      "predicted positive rate   0.175000  0.284722\n",
      "observed positive rate   0.237500  0.237500\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTENC # Use SMOTE for continuous data\n",
    "\n",
    "# Set up lists to hold results for each k-fold run\n",
    "replicate_accuracy = []\n",
    "replicate_precision = []\n",
    "replicate_recall = []\n",
    "replicate_f1 = []\n",
    "replicate_predicted_positive_rate = []\n",
    "replicate_observed_positive_rate = []\n",
    "\n",
    "# Set up splits\n",
    "number_of_splits = 10\n",
    "skf = StratifiedKFold(n_splits = number_of_splits)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "# Loop through the k-fold splits\n",
    "for train_index, test_index in skf.split(X_np, y_np):\n",
    "    \n",
    "    # Get X and Y train/test\n",
    "    X_train, X_test = X_np[train_index], X_np[test_index]\n",
    "    y_train, y_test = y_np[train_index], y_np[test_index]\n",
    "    \n",
    "    # Create an enhanced data set with SMOTENC\n",
    "    smote_nc = SMOTENC(categorical_features=categorical, random_state=42)\n",
    "    X_resampled, y_resampled = smote_nc.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Standardise X data\n",
    "    X_train_std, X_test_std = standardise_data(X_resampled, X_test)\n",
    "    \n",
    "    # Set up and fit model\n",
    "    model = LogisticRegression(solver='lbfgs')\n",
    "    model.fit(X_train_std, y_resampled)\n",
    "    \n",
    "    # Predict training and test set labels\n",
    "    y_pred_train = model.predict(X_train_std)\n",
    "    y_pred_test = model.predict(X_test_std)\n",
    "    \n",
    "    # Predict test set labels and get accuracy scores\n",
    "    y_pred_test = model.predict(X_test_std)\n",
    "    accuracy_scores = calculate_accuracy(y_test, y_pred_test)\n",
    "    replicate_accuracy.append(accuracy_scores['accuracy'])\n",
    "    replicate_precision.append(accuracy_scores['precision'])\n",
    "    replicate_recall.append(accuracy_scores['recall'])\n",
    "    replicate_f1.append(accuracy_scores['f1'])\n",
    "    replicate_predicted_positive_rate.append(\n",
    "        accuracy_scores['predicted_positive_rate'])\n",
    "    replicate_observed_positive_rate.append(\n",
    "        accuracy_scores['observed_positive_rate'])\n",
    "    \n",
    "# Transfer results to list and add to data frame\n",
    "non_smote_results = [np.mean(replicate_accuracy),\n",
    "                     np.mean(replicate_precision),\n",
    "                     np.mean(replicate_recall),\n",
    "                     np.mean(replicate_f1),\n",
    "                     np.mean(replicate_predicted_positive_rate),\n",
    "                     np.mean(replicate_observed_positive_rate)]\n",
    "\n",
    "results['smote'] = non_smote_results\n",
    "\n",
    "print (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "* Accuracy is highest with non-enhanced data\n",
    "* The minority class is under-predicted using non-enhanced data\n",
    "* Using SMOTE increases recall (detection of the minority class, the survivors), but now leads to an over-prediction of survivors.\n",
    "* SMOTE is useful if detection of the minority class is important, but may lead to more false positives.\n",
    "* SMOTE may be fined-tuned by passing a dictionary of the required numbers for each class. This will help to prevent a bias towards the minority class occurring. We demonstrate this below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning SMOTE\n",
    "\n",
    "By default, SMOTE rebalances the data set, synthetically enhancing the minority class so that the number of minority examples are increased to match the number of majority samples. Following on from the observation above that SMOTE may over-compensate and lead to over-estimation of the occurrence of the minority class, here we will fine-tune SMOTE by passing a dictionary of values for both the majority class (died), and the minority class (died). We will fix SMOTE to return 500 passengers who died, and vary the number of passengers who survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build a list of alternative balances of died:survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{0: 500, 1: 150}, {0: 500, 1: 200}, {0: 500, 1: 250}, {0: 500, 1: 300}, {0: 500, 1: 350}, {0: 500, 1: 400}, {0: 500, 1: 450}, {0: 500, 1: 500}]\n"
     ]
    }
   ],
   "source": [
    "smote_alterantive_samples = []\n",
    "survived_sample_sizes = list(range(150, 501, 50))\n",
    "\n",
    "for sample_size in survived_sample_sizes:\n",
    "    smote_input = dict()\n",
    "    smote_input[0] = 500 # always have 500 died passengers in retruened sample\n",
    "    smote_input[1] = sample_size\n",
    "    smote_alterantive_samples.append(smote_input)\n",
    "    \n",
    "# Show resulting list\n",
    "print (smote_alterantive_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run SMOTE with alternative sampling schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NumPy arrays of X and y (required for k-fold)\n",
    "X_np = X.values\n",
    "y_np = y.values\n",
    "\n",
    "# Create lists for overall results\n",
    "\n",
    "results_accuracy = []\n",
    "results_precision = []\n",
    "results_recall = []\n",
    "results_f1 = []\n",
    "results_predicted_positive_rate = []\n",
    "results_observed_positive_rate = []\n",
    "\n",
    "# Loop through list of alternative SMOTE sample sizes\n",
    "\n",
    "for sample_dict in smote_alterantive_samples:\n",
    "    \n",
    "    # Create lists for k-fold results\n",
    "    kfold_accuracy = []\n",
    "    kfold_precision = []\n",
    "    kfold_recall = []\n",
    "    kfold_f1 = []\n",
    "    kfold_predicted_positive_rate = []\n",
    "    kfold_observed_positive_rate = []\n",
    "    \n",
    "    # Set up k-fold training/test splits\n",
    "    number_of_splits = 5\n",
    "    skf = StratifiedKFold(n_splits = number_of_splits)\n",
    "    skf.get_n_splits(X_np, y_np)\n",
    "    \n",
    "    # Loop through the k-fold splits\n",
    "    for train_index, test_index in skf.split(X_np, y_np):\n",
    "\n",
    "        # Get X and Y train/test\n",
    "        X_train, X_test = X_np[train_index], X_np[test_index]\n",
    "        y_train, y_test = y_np[train_index], y_np[test_index]\n",
    "\n",
    "        # Get X and Y train/test\n",
    "        X_train_std, X_test_std = standardise_data(X_train, X_test)\n",
    "        \n",
    "        # Create an enhanced data set with SMOTENC\n",
    "        smote_nc = SMOTENC(categorical_features=categorical, \n",
    "                           sampling_strategy=sample_dict,\n",
    "                           random_state=42)\n",
    "        X_resampled, y_resampled = smote_nc.fit_resample(X_train, y_train)\n",
    "\n",
    "        # Standardise X data\n",
    "        X_train_std, X_test_std = standardise_data(X_resampled, X_test)\n",
    "\n",
    "        # Set up and fit model\n",
    "        model = LogisticRegression(solver='lbfgs')\n",
    "        model.fit(X_train_std, y_resampled)\n",
    " \n",
    "        # Predict test set labels and get accuracy scores\n",
    "        y_pred_test = model.predict(X_test_std)\n",
    "        accuracy_scores = calculate_accuracy(y_test, y_pred_test)\n",
    "        kfold_accuracy.append(accuracy_scores['accuracy'])\n",
    "        kfold_precision.append(accuracy_scores['precision'])\n",
    "        kfold_recall.append(accuracy_scores['recall'])\n",
    "        kfold_f1.append(accuracy_scores['f1'])\n",
    "        kfold_predicted_positive_rate.append(\n",
    "            accuracy_scores['predicted_positive_rate'])\n",
    "        kfold_observed_positive_rate.append(\n",
    "            accuracy_scores['observed_positive_rate'])\n",
    "                        \n",
    "    # Add mean results to overall results\n",
    "    results_accuracy.append(np.mean(kfold_accuracy))\n",
    "    results_precision.append(np.mean(kfold_precision))\n",
    "    results_recall.append(np.mean(kfold_recall))\n",
    "    results_f1.append(np.mean(kfold_f1))\n",
    "    results_predicted_positive_rate.append(\n",
    "        np.mean(kfold_predicted_positive_rate))\n",
    "    results_observed_positive_rate.append(\n",
    "        np.mean(kfold_observed_positive_rate))\n",
    "\n",
    "# Transfer results to dataframe\n",
    "results = pd.DataFrame(survived_sample_sizes, columns=['sample_size'])\n",
    "results['accuracy'] = results_accuracy\n",
    "results['precision'] = results_precision\n",
    "results['recall'] = results_recall\n",
    "results['f1'] = results_f1\n",
    "results['predicted_positive_rate'] = results_predicted_positive_rate\n",
    "results['observed_positive_rate'] = results_observed_positive_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>predicted_positive_rate</th>\n",
       "      <th>observed_positive_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0.848611</td>\n",
       "      <td>0.753090</td>\n",
       "      <td>0.550252</td>\n",
       "      <td>0.632081</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.2375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.841667</td>\n",
       "      <td>0.689584</td>\n",
       "      <td>0.620168</td>\n",
       "      <td>0.649474</td>\n",
       "      <td>0.215278</td>\n",
       "      <td>0.2375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>0.840278</td>\n",
       "      <td>0.670522</td>\n",
       "      <td>0.661345</td>\n",
       "      <td>0.662391</td>\n",
       "      <td>0.236111</td>\n",
       "      <td>0.2375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>0.836111</td>\n",
       "      <td>0.655294</td>\n",
       "      <td>0.678992</td>\n",
       "      <td>0.661999</td>\n",
       "      <td>0.248611</td>\n",
       "      <td>0.2375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>350</td>\n",
       "      <td>0.834722</td>\n",
       "      <td>0.644504</td>\n",
       "      <td>0.702353</td>\n",
       "      <td>0.668622</td>\n",
       "      <td>0.261111</td>\n",
       "      <td>0.2375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>400</td>\n",
       "      <td>0.827778</td>\n",
       "      <td>0.630362</td>\n",
       "      <td>0.702353</td>\n",
       "      <td>0.659806</td>\n",
       "      <td>0.268056</td>\n",
       "      <td>0.2375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>450</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.612461</td>\n",
       "      <td>0.702353</td>\n",
       "      <td>0.649153</td>\n",
       "      <td>0.276389</td>\n",
       "      <td>0.2375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>500</td>\n",
       "      <td>0.815278</td>\n",
       "      <td>0.601037</td>\n",
       "      <td>0.708235</td>\n",
       "      <td>0.645364</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.2375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_size  accuracy  precision    recall        f1  \\\n",
       "0          150  0.848611   0.753090  0.550252  0.632081   \n",
       "1          200  0.841667   0.689584  0.620168  0.649474   \n",
       "2          250  0.840278   0.670522  0.661345  0.662391   \n",
       "3          300  0.836111   0.655294  0.678992  0.661999   \n",
       "4          350  0.834722   0.644504  0.702353  0.668622   \n",
       "5          400  0.827778   0.630362  0.702353  0.659806   \n",
       "6          450  0.819444   0.612461  0.702353  0.649153   \n",
       "7          500  0.815278   0.601037  0.708235  0.645364   \n",
       "\n",
       "   predicted_positive_rate  observed_positive_rate  \n",
       "0                 0.175000                  0.2375  \n",
       "1                 0.215278                  0.2375  \n",
       "2                 0.236111                  0.2375  \n",
       "3                 0.248611                  0.2375  \n",
       "4                 0.261111                  0.2375  \n",
       "5                 0.268056                  0.2375  \n",
       "6                 0.276389                  0.2375  \n",
       "7                 0.283333                  0.2375  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "chart_x = results['sample_size']\n",
    "\n",
    "plt.plot(chart_x, results['accuracy'],\n",
    "         linestyle = '-',\n",
    "         label = 'Accuracy')\n",
    "\n",
    "plt.plot(chart_x, results['precision'],\n",
    "         linestyle = '--',\n",
    "         label = 'Precision')\n",
    "\n",
    "plt.plot(chart_x, results['recall'],\n",
    "         linestyle = '-.',\n",
    "         label = 'Recall')\n",
    "\n",
    "plt.plot(chart_x, results['f1'],\n",
    "         linestyle = ':',\n",
    "         label = 'F1')\n",
    "\n",
    "plt.plot(chart_x, results['predicted_positive_rate'],\n",
    "         linestyle = '-',\n",
    "         label = 'Predicted positive rate')\n",
    "\n",
    "plt.plot(chart_x, results['observed_positive_rate'],\n",
    "         linestyle = '--',\n",
    "         color='k',\n",
    "         label = 'Observed positive rate')\n",
    "\n",
    "\n",
    "plt.xlabel('SMOTE minority sampel size')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(-0.02, 1.02)\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we can see that we can adjust the SMOTE enhancement to return 250 minority class ('survived') samples in order to balance precision and recall, and to create a model that correctly predicts the proportion of passengers surviving."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
