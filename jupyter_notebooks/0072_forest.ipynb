{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forests\n",
    "\n",
    "Random forest is a versatile machine learning method based on decision trees. One useful feature of random forests is that it is easy to obtain the relative importance of features. This may be used to help better understand what drives classification, and may also be used to reduce the feature set used with minimal reduction in accuracy. \n",
    "\n",
    "Once again we will re-use our logistic regression model, and replace the model function wit the following three lines:\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    model = RandomForestClassifier(n_estimators=10000,\n",
    "                                random_state=0,\n",
    "                                n_jobs=-1)\n",
    "    model.fit (X,y)\n",
    "\n",
    "We will also add a function to print out relative importance of features. These are obtained using <em>model.feature_importances_</em>.\n",
    "\n",
    "Unlike many other methods, random forests do not need data to be normalised (though it won't cause any problems if you do)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Machine learning diagnostic performance measures:\n",
      "-------------------------------------------------\n",
      "accuracy = 0.972\n",
      "sensitivity = 0.967\n",
      "specificity = 0.981\n",
      "positive_likelihood = 51.233\n",
      "negative_likelihood = 0.034\n",
      "false_positive_rate = 0.019\n",
      "false_negative_rate = 0.033\n",
      "positive_predictive_value = 0.989\n",
      "negative_predictive_value = 0.945\n",
      "precision = 0.989\n",
      "recall = 0.967\n",
      "f1 = 0.978\n",
      "positive_rate = 0.615\n",
      "\n",
      "Feature importances:\n",
      "--------------------\n",
      "                    feature  importance\n",
      "22          worst perimeter    0.128502\n",
      "7       mean concave points    0.122821\n",
      "27     worst concave points    0.121434\n",
      "23               worst area    0.102040\n",
      "20             worst radius    0.099788\n",
      "6            mean concavity    0.054834\n",
      "2            mean perimeter    0.046540\n",
      "3                 mean area    0.039068\n",
      "13               area error    0.039064\n",
      "0               mean radius    0.036952\n",
      "26          worst concavity    0.034057\n",
      "25        worst compactness    0.017705\n",
      "10             radius error    0.016905\n",
      "21            worst texture    0.016596\n",
      "1              mean texture    0.014762\n",
      "5          mean compactness    0.013044\n",
      "12          perimeter error    0.012706\n",
      "24         worst smoothness    0.012666\n",
      "28           worst symmetry    0.012059\n",
      "29  worst fractal dimension    0.006879\n",
      "16          concavity error    0.006393\n",
      "4           mean smoothness    0.005968\n",
      "17     concave points error    0.005948\n",
      "19  fractal dimension error    0.005639\n",
      "11            texture error    0.005319\n",
      "15        compactness error    0.005317\n",
      "8             mean symmetry    0.004822\n",
      "18           symmetry error    0.004448\n",
      "14         smoothness error    0.004105\n",
      "9    mean fractal dimension    0.003617\n"
     ]
    }
   ],
   "source": [
    "# import required modules\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_diagnostic_performance (actual_predicted):\n",
    "    \"\"\" Calculate diagnostic performance.\n",
    "    \n",
    "    Takes a Numpy array of 1 and zero, two columns: actual and predicted\n",
    "    \n",
    "    Note that some statistics are repeats with different names\n",
    "    (precision = positive_predictive_value and recall = sensitivity).\n",
    "    Both names are returned\n",
    "    \n",
    "    Returns a dictionary of results:\n",
    "        \n",
    "    1) accuracy: proportion of test results that are correct    \n",
    "    2) sensitivity: proportion of true +ve identified\n",
    "    3) specificity: proportion of true -ve identified\n",
    "    4) positive likelihood: increased probability of true +ve if test +ve\n",
    "    5) negative likelihood: reduced probability of true +ve if test -ve\n",
    "    6) false positive rate: proportion of false +ves in true -ve patients\n",
    "    7) false negative rate:  proportion of false -ves in true +ve patients\n",
    "    8) positive predictive value: chance of true +ve if test +ve\n",
    "    9) negative predictive value: chance of true -ve if test -ve\n",
    "    10) precision = positive predictive value \n",
    "    11) recall = sensitivity\n",
    "    12) f1 = (2 * precision * recall) / (precision + recall)\n",
    "    13) positive rate = rate of true +ve (not strictly a performance measure)\n",
    "    \"\"\"\n",
    "    # Calculate results\n",
    "    actual_positives = actual_predicted[:, 0] == 1\n",
    "    actual_negatives = actual_predicted[:, 0] == 0\n",
    "    test_positives = actual_predicted[:, 1] == 1\n",
    "    test_negatives = actual_predicted[:, 1] == 0\n",
    "    test_correct = actual_predicted[:, 0] == actual_predicted[:, 1]\n",
    "    accuracy = np.average(test_correct)\n",
    "    true_positives = actual_positives & test_positives\n",
    "    true_negatives = actual_negatives & test_negatives\n",
    "    sensitivity = np.sum(true_positives) / np.sum(actual_positives)\n",
    "    specificity = np.sum(true_negatives) / np.sum(actual_negatives)\n",
    "    positive_likelihood = sensitivity / (1 - specificity)\n",
    "    negative_likelihood = (1 - sensitivity) / specificity\n",
    "    false_positive_rate = 1 - specificity\n",
    "    false_negative_rate = 1 - sensitivity\n",
    "    positive_predictive_value = np.sum(true_positives) / np.sum(test_positives)\n",
    "    negative_predictive_value = np.sum(true_negatives) / np.sum(test_negatives)\n",
    "    precision = positive_predictive_value\n",
    "    recall = sensitivity\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    positive_rate = np.mean(actual_predicted[:,1])\n",
    "    \n",
    "    # Add results to dictionary\n",
    "    performance = {}\n",
    "    performance['accuracy'] = accuracy\n",
    "    performance['sensitivity'] = sensitivity\n",
    "    performance['specificity'] = specificity\n",
    "    performance['positive_likelihood'] = positive_likelihood\n",
    "    performance['negative_likelihood'] = negative_likelihood\n",
    "    performance['false_positive_rate'] = false_positive_rate\n",
    "    performance['false_negative_rate'] = false_negative_rate\n",
    "    performance['positive_predictive_value'] = positive_predictive_value\n",
    "    performance['negative_predictive_value'] = negative_predictive_value\n",
    "    performance['precision'] = precision\n",
    "    performance['recall'] = recall\n",
    "    performance['f1'] = f1\n",
    "    performance['positive_rate'] = positive_rate\n",
    "\n",
    "    return performance\n",
    "\n",
    "def load_data ():\n",
    "    \"\"\"Load the data set. Here we load the Breast Cancer Wisconsin (Diagnostic)\n",
    "    Data Set. Data could be loaded from other sources though the structure\n",
    "    should be compatible with thi sdata set, that is an object with the \n",
    "    following attribtes:\n",
    "        .data (holds feature data)\n",
    "        .feature_names (holds feature titles)\n",
    "        .target_names (holds outcome classification names)\n",
    "        .target (holds classification as zero-based number)\n",
    "        .DESCR (holds text-based description of data set)\"\"\"\n",
    "    \n",
    "    data_set = datasets.load_breast_cancer()\n",
    "    return data_set\n",
    "\n",
    "def normalise (X_train,X_test):\n",
    "    \"\"\"Normalise X data, so that training set has mean of zero and standard\n",
    "    deviation of one\"\"\"\n",
    "    \n",
    "    # Initialise a new scaling object for normalising input data\n",
    "    sc=StandardScaler() \n",
    "    # Set up the scaler just on the training set\n",
    "    sc.fit(X_train)\n",
    "    # Apply the scaler to the training and test sets\n",
    "    X_train_std=sc.transform(X_train)\n",
    "    X_test_std=sc.transform(X_test)\n",
    "    return X_train_std, X_test_std\n",
    "\n",
    "\n",
    "def print_diagnostic_results (performance):\n",
    "    \"\"\"Iterate through, and print, the performance metrics dictionary\"\"\"\n",
    "    \n",
    "    print('\\nMachine learning diagnostic performance measures:')\n",
    "    print('-------------------------------------------------')\n",
    "    for key, value in performance.items():\n",
    "        print (key,'= %0.3f' %value) # print 3 decimal places\n",
    "    return\n",
    "\n",
    "def print_feaure_importances (model, features):\n",
    "    print ()\n",
    "    print ('Feature importances:')\n",
    "    print ('--------------------')\n",
    "    df = pd.DataFrame()\n",
    "    df['feature'] = features\n",
    "    df['importance'] = model.feature_importances_\n",
    "    df = df.sort_values('importance', ascending = False)\n",
    "    print (df)\n",
    "    return\n",
    "\n",
    "def split_data (data_set, split=0.25):\n",
    "    \"\"\"Extract X and y data from data_set object, and split into tarining and\n",
    "    test data. Split defaults to 75% training, 25% test if not other value \n",
    "    passed to function\"\"\"\n",
    "    \n",
    "    X=data_set.data\n",
    "    y=data_set.target\n",
    "    X_train,X_test,y_train,y_test=train_test_split(\n",
    "        X,y,test_size=split, random_state=0)\n",
    "    return X_train,X_test,y_train,y_test\n",
    "\n",
    "def test_model(model, X, y):\n",
    "    \"\"\"Return predicted y given X (attributes)\"\"\"\n",
    "    \n",
    "    y_pred = model.predict(X)\n",
    "    test_results = np.vstack((y, y_pred)).T\n",
    "    return test_results\n",
    "\n",
    "def train_model (X, y):\n",
    "    \"\"\"Train the model \"\"\"\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    model = RandomForestClassifier(n_estimators=10000,\n",
    "                                random_state=0,\n",
    "                                n_jobs=-1)\n",
    "    model.fit (X,y)\n",
    "    return model\n",
    "\n",
    "###### Main code #######\n",
    "\n",
    "# Load data\n",
    "data_set = load_data()\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train,X_test,y_train,y_test = split_data(data_set, 0.25)\n",
    "\n",
    "# Normalise data (not needed for Random Forests)\n",
    "# X_train_std, X_test_std = normalise(X_train,X_test)\n",
    "\n",
    "# Train model\n",
    "model = train_model(X_train, y_train)\n",
    "\n",
    "# Produce results for test set\n",
    "test_results = test_model(model, X_test, y_test)\n",
    "\n",
    "# Measure performance of test set predictions\n",
    "performance = calculate_diagnostic_performance(test_results)\n",
    "\n",
    "# Print performance metrics\n",
    "print_diagnostic_results(performance)\n",
    "\n",
    "# Print feature importances\n",
    "print_feaure_importances (model, data_set.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
